\chapter{Evaluation}
\label{ch:evaluation}

Boosting bringt meist ein bisschen was, aber weniger als erwartet
NBC und DTC tuen sich schwer bei nicht separierbaren Problemen (Datensätze nicht in in Report aufgenommen) - interessant wären Ansätze wie KNN oder SVM
AdaBoost hat einige Schwachstellen (negativ bewertete Hypothesen können mehr aussagen als positiv bewertete, overfitting)

The first interesting fact is that even thought NBC is a very weak classifier, the results are quite satisfying even without boosting. 
All the data sets contain multi class problems, for example the data set \emph{vowel-context} (table \ref{tab:vowel-context}) 
has 11 different labels, so the apriori probability for a class would be 9,1\%.
One single NBC still classifies 64\% of the test instances correctly. However, the improvement with increasing number of NBCs
is not very big. In some cases like \emph{pendigits} (table \ref{tab:pendigits}) there is even a decrease of the test accuracy from 10 to 20 NBCs.
The reason for that might be that the weight of a hypothesis is not computed on the basis of the majority of instances but on their weights. 
In case when only few instances could be classified by a hypothesis the hypothesis still can have a big weight when these instances also have big weights.

DTC has proved to be better than NBC. In data sets shown above DTC is about 3-8\% better than NBC. This is reasonable because NBC uses
the naive assumption that all of the features are conditionally independent of one another. DTC considers the dependencies and is
therefore better. At least, when the decision tree is deep enough. As shown in \emph{pendigits} (table \ref{tab:pendigits}) and 
\emph{segment} (table \ref{tab:segment}) the performance of DTC is very poor at depth 1. Similar to NBC, there is only single digit
percentage increase after using a higher number of hypotheses.

Not only a low depth of the decision tree can lead to unsufficient results but also a high one. In this case the
classifier is overspecialized. This leads to very good results during the training phase but not in the tests. 
Fortunately, the data sets we use don't suffer from this problem. So, even the infinit depth leads to good results
during the tests.

Unfortunately, there is no increase in accuracy after using both classifiers. The reason for that is that after NBC is done 
classifying, the weights of most instances are very small so that DTC only concentrates on "bad" or inconsistent instances. 
Additionally, the depth of DTC is only 2 which is not as good as infinit depth.

The difference between train and test accuracy is partly huge. The reason for that is that for the average training accuracy all 
hypotheses are considered equal, that means that their weights aren't taken into account. So, even if a hypothesis is right for very
few instances it still counts the same lika a hypothesis that is right for almost all instances.

With increasing number of hypotheses the average train accuracy decreases and the standard deviation increases. This shows that 
the later hypotheses are specialized for only few instances and are bad for the majority of the data. However, the weight of 
these hypotheses should be smaller than of the earlier hypothese. Figure \ref{fig:weightDiagramm} shows the distribution of the weights.

\begin{figure}[h]
  \centering
  \includegraphics[height=0.35\textheight]{images/weightDiagramm}
  \caption{Distribution of the hypotheses' weights}
  \label{fig:weightDiagramm}
\end{figure}

AdaBoost has problems with inconsistent data. Early in the project we tried both NBC and DTC with data sets which contained instances with the same
values but different labels. After a few rounds of boosting the inconsistend instances gained so much weight that it was impossible for the other 
instances to "recover". Therefore, after a curtain point, all classifiers concentrated only on the inconsistent data and were not able to produce 
a proper hypothesis. We think, a detailed preprocessing of the complete data set would improve the results and make AdaBoost more stable.

Also, dividing the real-number-features into bins has a great influence on the results. If there are too many bins then NBC and DTC would show 
almost 100\% accuracy on the training data but would perform poorly on the training set (overspecialization). On the other hand, if there are only 
a couple of bins then the statements made by the hypotheses are too general.

After all, AdaBoost has shown less improvement than expected. It would be interesting to see if other classifiers 
like Artificial Neural Networks or Support Vector Machines could improve the performance of AdaBoost. Also, more attetion
should be directed to the preprocessing because it can play the crucial role in optimizing the results.